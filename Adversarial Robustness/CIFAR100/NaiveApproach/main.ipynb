{"cells":[{"cell_type":"markdown","metadata":{"id":"K3Hn6KmhsN7k"},"source":["Architecture based on the solution proposed in https://arxiv.org/pdf/1911.00937.pdf , appendix D.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6830,"status":"ok","timestamp":1679769322596,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"7mKXVkHOdxm8","outputId":"d9a207f4-a838-46b4-a955-404a8bd63932"},"outputs":[],"source":["pip install foolbox"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4311,"status":"ok","timestamp":1679769326891,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"gff6yPqRb-0j","outputId":"3f13631d-3923-41f7-c007-1c7a95f11448"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import numpy as np\n","import foolbox as fb\n","import time\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from utils import *\n","from multiClassHinge import multiClassHingeLoss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1679769326891,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"4IzWxQnwd17-","outputId":"efc64308-3143-412e-fc0b-8b1c4ccc2d25"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1679769357674,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"rAFKcwXLeCta"},"outputs":[],"source":["transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) #cifar100\n","])\n","\n","# Normalize the test set same as training set without augmentation\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) #cifar100\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11962,"status":"ok","timestamp":1679769369633,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"4qiIxYcJeLxF","outputId":"4309dac2-c2dd-462d-c397-a5a18ed8b0b0"},"outputs":[],"source":["batch_size = 128\n","\n","n_classes = 10\n","\n","trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n","                                        download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n","                                       download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1679769369636,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"vjHyJDvZFTZ6"},"outputs":[],"source":["class CNNBlock(nn.Module):\n","    def __init__(self, in_chan, out_chan, kernel_size, padding, shape):\n","        super(CNNBlock, self).__init__()\n","\n","        self.shape = shape\n","        self.conv = nn.Conv2d(in_chan, out_chan, kernel_size=kernel_size, padding=padding)\n","        self.storedEigVect = torch.rand(in_chan,shape[0], shape[1])\n","\n","    def reg(self,):\n","      return deconv_orth_dist(torch.transpose(self.conv.weight,0,1))\n","\n","    def forward(self,x):\n","      return self.conv(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4254,"status":"ok","timestamp":1679769373871,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"QRJHqpf1cBVI"},"outputs":[],"source":["dt = 1 # standard ResNET\n","\n","class CNNBlock2(nn.Module):\n","    def __init__(self, in_chan, nf, n_layers):\n","        super(CNNBlock2, self).__init__()\n","\n","        self.nlayers = n_layers\n","        self.nf = nf\n","        self.chans = in_chan\n","\n","        self.matrices = self.nlayers\n","\n","        self.conv1 = conv_block(self.chans, self.nf,pool=False)\n","        self.convs = nn.ModuleList([nn.Conv2d(self.nf, self.nf,3,1,1,bias=True) for i in range(self.matrices)])\n","        self.convsO = nn.ModuleList([nn.Conv2d(self.nf, self.nf,3,1,1,bias=False) for i in range(self.matrices)])\n","\n","        for i in range(len(self.convs)):\n","          makeDeltaOrthogonal(self.convs[i].weight.data, nn.init.calculate_gain('leaky_relu',0))\n","          makeDeltaOrthogonal(self.convsO[i].weight.data, nn.init.calculate_gain('leaky_relu',0))\n","\n","        self.mp = nn.MaxPool2d(2,2)\n","\n","    def getReg(self,):\n","        reg = 0\n","        for i in range(self.nlayers):\n","            reg += deconv_orth_dist(self.convs[i].weight) + deconv_orth_dist(self.convsO[i].weight)\n","        return reg\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","\n","        count = 0\n","\n","        #cc = Positive(self.ells)\n","\n","        for i in np.arange(0,self.matrices):\n","          A = self.convs[i]\n","          B = self.convsO[i]\n","          x = 0.5 * (x + dt * B(torch.relu(A(x))))\n","\n","        x = self.mp(x)\n","        return x\n","\n","class CNN(nn.Module):\n","    def __init__(self, in_chan, nf1, nf2, nf3, n_l1, n_l2, n_l3):\n","        super(CNN, self).__init__()\n","\n","        self.input = in_chan\n","        self.nf1 = nf1\n","        self.nf2 = nf2\n","        self.nf3 = nf3\n","        self.n_l1 = n_l1\n","        self.n_l2 = n_l2\n","        self.n_l3 = n_l3\n","\n","        self.seq = nn.Sequential(\n","            CNNBlock2(self.input,self.nf1,self.n_l1),\n","            CNNBlock2(self.nf1,self.nf2,self.n_l2),\n","            CNNBlock2(self.nf2,self.nf3,self.n_l3),\n","            nn.Flatten()\n","          )\n","        self.lin = nn.Linear(2048,100)\n"," \n","    def getReg(self,):\n","        \n","        return self.seq[0].getReg() + self.seq[1].getReg() + self.seq[2].getReg()\n","\n","    def forward(self,x):\n","      x = self.seq(x)\n","      x = self.lin(x)\n","      return x\n","\n","model = CNN(3,32,64,128,4,4,4)\n","model.to(device);"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1679769373871,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"O7PsRBhJBhOV","outputId":"44833487-cb3d-4382-eab7-0b3321e9da40"},"outputs":[],"source":["model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","params = sum([np.prod(p.size()) for p in model_parameters])\n","print(f\"The network has {params} trainable parameters\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1679769373872,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"cA9qF7cgBxdK"},"outputs":[],"source":["lr = 1e-3\n","momentum = 0.9\n","optimizer = 'stochastic gradient descent'\n","scheduler = 'stepLR'\n","step_size = 30\n","EPOCHS = 100\n","weight_decay = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1679769373873,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"oA2p1kO7B1hQ"},"outputs":[],"source":["class Normalisation(torch.nn.Module):\n","    def __init__(self, means=(0.485, 0.456, 0.406), stds=(0.229, 0.224, 0.225)): #cifar100\n","        super().__init__()\n","        assert len(means) == len(stds)\n","        self.means = means\n","        self.stds = stds\n","    \n","    def forward(self, x):\n","        return (x - torch.tensor(self.means, device=x.device).view(1, len(self.means), 1, 1)) / torch.tensor(self.stds, device=x.device).view(1, len(self.means), 1, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1679769373874,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"8TjUB78_CE-M"},"outputs":[],"source":["import torch.optim as optim\n","\n","marginList = [0.07,0.15,0.3]\n","epsilons = [0.0, 8/255, 16/255, 36/255, 0.3, 0.5, 0.6, 0.8, 1.0]\n","\n","robust_accuracy = np.zeros((len(marginList),len(epsilons)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"wp--bolGCGb_"},"outputs":[],"source":["for iterate,margin in enumerate(marginList):\n","\n","  model = CNN(3,32,64,128,4,4,4)\n","  model.to(device);\n","\n","  pretrained_dict = torch.load(f\"trained_model_{margin}_cifar10.pt\",map_location=device)\n","  model.load_state_dict(pretrained_dict, strict=False)\n","\n","  criterion = multiClassHingeLoss(margin = margin)\n","  optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n","  \n","  gamma = .01\n","\n","  EPOCHS = 100\n","  for epoch in range(EPOCHS):\n","      losses = []\n","      running_loss = 0\n","      correct = 0\n","      count = 0\n","      for i, inp in enumerate(trainloader):\n","          inputs, labels = inp\n","          inputs, labels = inputs.to(device), labels.to(device)\n","          optimizer.zero_grad()\n","      \n","          outputs = model(inputs)\n","          l1_reg = gamma * model.getReg()\n","          loss = criterion(outputs, labels)+l1_reg\n","          losses.append(loss.item())\n","          loss.backward()\n","\n","          optimizer.step()\n","          running_loss += loss.item()\n","\n","          if i%100 == 0 and i > 0:\n","              print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n","              running_loss = 0.0\n","      \n","      #Check current accuracy\n","      correct = 0\n","      total = 0\n","      # since we're not training, we don't need to calculate the gradients for our outputs\n","      \n","      model.eval()\n","      with torch.no_grad():\n","          \n","          norms = []\n","          regTerms = []\n","          for k in range(3):\n","            regTerms.append(model.seq[k].getReg().item())\n","            \n","          print(f\"Norms: {norms}\")\n","          print(f\"Orthogonality violation: {regTerms}\")\n","\n","\n","          for data in testloader:\n","              images, labels = data\n","              images.shape\n","              # calculate outputs by running images through the network\n","              outputs = model(images.to(device))\n","              # the class with the highest energy is what we choose as prediction\n","              _, predicted = torch.max(outputs.data, 1)\n","              total += labels.size(0)\n","              correct += (predicted == labels.to(device)).sum().item()\n","          print('Current accuracy on 10000 test images: %d %%' % (\n","              100 * correct / total))\n","      model.train()\n","      scheduler.step()\n","      if epoch%10 == 0 and epoch>0:\n","          lr=optimizer.param_groups[0][\"lr\"]\n","  print('Training Done')\n","\n","  model.eval();\n","  transform_test_rob = transforms.Compose([\n","    transforms.ToTensor()\n","  ])\n","  batch_size = 1024\n","  testset_rob = torchvision.datasets.CIFAR100(root='./data', train=False,\n","                                        download=True, transform=transform_test_rob)\n","  testloader_rob = torch.utils.data.DataLoader(testset_rob, batch_size=batch_size,\n","                                          shuffle=False, num_workers=2)\n","  images, labels = next(iter(testloader_rob))\n","  images, labels = images.to(device), labels.to(device)\n","  model = nn.Sequential(Normalisation(),model).eval()\n","  fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n","  \n","  acc = fb.utils.accuracy(fmodel, images, labels)\n","  attack = fb.attacks.L2PGD(steps=10)\n","  \n","  _, advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n","  robust_accuracy[iterate] = torch.mean((1-1.*success),axis=1).detach().cpu().numpy()\n","\n","  fig = plt.figure(figsize=(20,10))\n","  plt.plot(epsilons,robust_accuracy[iterate],'r-*',label=\"Experimental\")\n","  plt.xlabel(r\"$\\varepsilon$\",fontsize=20)\n","  plt.ylabel(\"Robust accuracy\",fontsize=20)\n","  plt.xticks(fontsize=20)\n","  plt.yticks(fontsize=20)\n","  plt.legend(fontsize=20,loc=1)\n","  plt.title(f\"L2 robustness. Trained with margin = {margin}. Test accuracy = {round(acc * 100,2)}%\",fontsize=20);\n","\n","  plt.savefig(f'Cifar100_L2margin_{margin}.png')\n","\n","  dataForTxt = robust_accuracy[iterate]\n","  destination = f\"Cifar100_updateMargin_{margin}.txt\"\n","  np.savetxt(destination, dataForTxt.reshape(-1,1))\n","\n","  torch.save(model.state_dict(), f\"trained_model_margin_{margin}.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FYVy_Hk1C0Wb"},"outputs":[],"source":["marginList = [0.07, 0.15,0.3]\n","epsilons = [0.0, 8/255, 16/255, 36/255, 0.3, 0.5, 0.6, 0.8, 1.0]\n","fig = plt.figure(figsize=(20,10))\n","for i in range(len(marginList)):\n","  plt.plot(epsilons,robust_accuracy[i],'-*',label=f\"Margin = {marginList[i]}\")\n","plt.xlabel(r\"$\\varepsilon$\",fontsize=20)\n","plt.ylabel(\"Robust accuracy\",fontsize=20)\n","plt.xticks(fontsize=20)\n","plt.yticks(fontsize=20)\n","plt.legend(fontsize=20,loc=1)\n","plt.title(f\"L2 robustness comparison CIFAR100\",fontsize=20);\n","plt.savefig(\"Cifar100_RobustnessCNN.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"c1K3a01XjXLK"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNXh1lCkChAoSj4C6VYlaQU","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.11.3 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
