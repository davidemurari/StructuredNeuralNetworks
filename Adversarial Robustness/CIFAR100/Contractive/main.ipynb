{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3810,"status":"ok","timestamp":1688568935145,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":-120},"id":"njvuXwo5upN0","outputId":"ff523282-96aa-4094-c9b0-36966d87a74b"},"outputs":[],"source":["pip install foolbox"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4406,"status":"ok","timestamp":1688568939546,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":-120},"id":"fpVIErl_ukJ5","outputId":"b63b3f9f-51d0-47f1-8132-b00c039fcb93"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import random\n","import foolbox as fb\n","import torch.optim as optim\n","\n","trainMode = True\n","constrain = True\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","from utils import *\n","from network import *\n","from training import *\n","from multiClassHinge import *\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2327,"status":"ok","timestamp":1688568941869,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":-120},"id":"78q50Tq3u6Tz","outputId":"bf3228e9-c5e5-4584-be88-191251183b0e"},"outputs":[],"source":["# Normalize the test set same as training set without augmentation\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) #cifar100\n","])\n","batch_size = 128\n","\n","trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n","                                        download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n","                                       download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)\n","a = 0.5\n","M = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3325,"status":"ok","timestamp":1688568945191,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":-120},"id":"QOGYxeR-eLbu","outputId":"8ae49972-e76f-467a-9380-33c4956feaf5"},"outputs":[],"source":["class Normalisation(torch.nn.Module):\n","    def __init__(self,means=(0.485, 0.456, 0.406), stds=(0.229, 0.224, 0.225)): #cifar100\n","        super().__init__()\n","        assert len(means) == len(stds)\n","        self.means = means\n","        self.stds = stds\n","\n","    def forward(self, x):\n","        return (x - torch.tensor(self.means, device=x.device).view(1, len(self.means), 1, 1)) / torch.tensor(self.stds, device=x.device).view(1, len(self.means), 1, 1)\n","\n","transform_test_rob = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","batch_size = 1024\n","testset_rob = torchvision.datasets.CIFAR100(root='./data', train=False,\n","                                      download=True, transform=transform_test_rob)\n","testloader_rob = torch.utils.data.DataLoader(testset_rob, batch_size=batch_size,\n","                                        shuffle=False, num_workers=2)\n","images, labels = next(iter(testloader_rob))\n","images, labels = images.to(device), labels.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"7al3dk8WMGry"},"outputs":[],"source":["marginList = [0.07,0.15,0.3]\n","epsilons = [0.0, 8/255, 16/255, 36/255, 0.3, 0.5, 0.6, 0.8, 1.0]\n","saveRobAcc = np.zeros((len(marginList),len(epsilons)))\n","it = 0\n","for num,margin in enumerate(marginList):\n","\n","  print(f\"\\n\\n Now we are working with margin = {margin}\\n\\n\")\n","\n","  net = Network(3,32,64,128,4,4,4,S = 2, a = a, M=M)\n","  net.to(device);\n","  pretrained_dict = torch.load(f\"CertifiedLip_margin_{margin}_cifar10.pt\",map_location=device)\n","  net.load_state_dict(pretrained_dict, strict=False)\n","\n","  criterion = multiClassHingeLoss(margin = margin)\n","  lr = 1e-4\n","\n","  optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.9)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n","\n","  model_save_name = f'CertifiedLip_margin_{margin}.pt'\n","  path = F\"{model_save_name}\"\n","\n","  if trainMode:\n","    loss = -1\n","    while loss<0:\n","      print(f\"Training with learning rate {lr}\")\n","      loss = train(net, margin, criterion, optimizer, scheduler, trainloader, testloader, device, epochs=100, reg=True, a=a, constrain = constrain, gamma = 1)\n","      if loss<0:\n","        net = Network(3,32,64,128,4,4,4,S=2,a=a,M=M)\n","        net.to(device);\n","        lr/=10\n","        optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.9)#,weight_decay=1e-4)\n","        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n","\n","\n","    torch.save(net.state_dict(), path)\n","\n","  else:\n","    net.load_state_dict(torch.load(path))\n","\n","  model = nn.Sequential(Normalisation(),net).eval()\n","  fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n","\n","  acc = fb.utils.accuracy(fmodel, images, labels)\n","\n","  attack = fb.attacks.L2PGD(steps=10)\n","  _, advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n","  robust_accuracy = torch.mean((1-1.*success),axis=1)\n","  saveRobAcc[num] = robust_accuracy.detach().cpu().numpy()\n","\n","  it += 1\n","  destination = f\"updateMargin_{margin}.txt\"\n","  np.savetxt(destination, saveRobAcc.reshape(-1,1))\n","\n","  fig = plt.figure(figsize=(20,10))\n","  plt.plot(epsilons,robust_accuracy.detach().cpu().numpy(),'r-*',label=\"Experimental\")\n","  plt.xlabel(r\"$\\varepsilon$\",fontsize=20)\n","  plt.ylabel(\"Robust accuracy\",fontsize=20)\n","  plt.xticks(fontsize=20)\n","  plt.yticks(fontsize=20)\n","  plt.legend(fontsize=20,loc=1)\n","  plt.title(f\"L2 robustness. Trained with margin = {margin}. Test accuracy = {round(acc * 100,2)}%\",fontsize=20);\n","\n","  plt.savefig(f'L2margin_{margin}.png')\n","\n","fig = plt.figure(figsize=(20,10))\n","\n","for i in range(len(marginList)):\n","  plt.plot(epsilons,saveRobAcc[i],'-*',label=f\"Margin = {marginList[i]}\")\n","\n","plt.xlabel(r\"$\\varepsilon$\",fontsize=20)\n","plt.ylabel(\"Robust accuracy\",fontsize=20)\n","plt.xticks(fontsize=20)\n","plt.yticks(fontsize=20)\n","plt.legend(fontsize=20,loc=1)\n","plt.title(f\"L2 robustness comparison CIFAR100\",fontsize=20);\n","\n","plt.savefig(f'L2RobustnessComparison.png')"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","provenance":[{"file_id":"1uXPS9TivF3IwSUjUcF4lqfdqvyEHAq3R","timestamp":1644397343349}],"version":""},"kernelspec":{"display_name":"Python 3.11.3 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
