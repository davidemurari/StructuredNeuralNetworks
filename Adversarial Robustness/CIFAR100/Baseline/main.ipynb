{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5469,"status":"ok","timestamp":1679695707869,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"67U79zgW_a-_","outputId":"00abb3a3-aef6-43c0-d83c-5c7da7aff488"},"outputs":[],"source":["pip install foolbox"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3888,"status":"ok","timestamp":1679695711752,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"GG41mD746n6X","outputId":"bf2e446e-bf84-4a7e-c788-934ce1b731bf"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import numpy as np\n","import foolbox as fb\n","import time\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1679695711752,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"Oab5uKEP7S3l","outputId":"62607475-9a20-454c-e136-40047bdd2993"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1679696160880,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"jeSmKznI6tqx"},"outputs":[],"source":["transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) #cifar100\n","])\n","\n","# Normalize the test set same as training set without augmentation\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) #cifar100\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15575,"status":"ok","timestamp":1679696176424,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"TD0L2yF-65Us","outputId":"522bf82f-ad4f-4948-d7ee-04ac9c1474af"},"outputs":[],"source":["batch_size = 128\n","\n","trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n","                                        download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n","                                       download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1679696176425,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"QmNxC1xNN10f"},"outputs":[],"source":["import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1679696176426,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"L5ukiQfCCFZ0"},"outputs":[],"source":["def conv_block(in_channels, out_channels, pool=False):\n","    convo = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n","    layers = [convo]\n","    if pool: layers.append(nn.MaxPool2d(2))\n","    return nn.Sequential(*layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1679696673791,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"rzFoK6qd-lee"},"outputs":[],"source":["dt = 1 # standard ResNET\n","\n","class ResNet(nn.Module):\n","    def __init__(self, in_chan, nf, n_layers):\n","        super(ResNet, self).__init__()\n","\n","        self.nlayers = n_layers\n","        self.nf = nf\n","        self.chans = in_chan\n","\n","        self.matrices = self.nlayers\n","\n","        self.conv1 = conv_block(self.chans, self.nf,pool=False)\n","        self.convs = nn.ModuleList([nn.Conv2d(self.nf, self.nf,3,1,1,bias=True) for i in range(self.matrices)])\n","        self.convsO = nn.ModuleList([nn.Conv2d(self.nf, self.nf,3,1,1,bias=False) for i in range(self.matrices)])\n","\n","        self.mp = nn.MaxPool2d(2,2)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","\n","        count = 0\n","\n","        for i in np.arange(0,self.matrices):\n","          A = self.convs[i]\n","          B = self.convsO[i]\n","          x = x + dt * B(torch.relu(((A(x)))))\n","\n","        x = self.mp(x)\n","        return x\n","\n","class Network2(nn.Module):\n","    def __init__(self, in_chan, nf1, nf2, nf3, n_l1, n_l2, n_l3):\n","        super(Network2, self).__init__()\n","\n","        self.input = in_chan\n","        self.nf1 = nf1\n","        self.nf2 = nf2\n","        self.nf3 = nf3\n","        self.n_l1 = n_l1\n","        self.n_l2 = n_l2\n","        self.n_l3 = n_l3\n","\n","        self.seq = nn.Sequential(\n","            ResNet(self.input,self.nf1,self.n_l1),\n","            ResNet(self.nf1,self.nf2,self.n_l2),\n","            ResNet(self.nf2,self.nf3,self.n_l3),\n","            nn.Flatten(),\n","            nn.Linear(2048,100)\n","          )\n"," \n","    def forward(self,x):\n","      x = self.seq(x)\n","      return x"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679696675568,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"h-ej_ODyPmop"},"outputs":[],"source":["lr = 1e-2\n","momentum = 0.9\n","optimizer = 'stochastic gradient descent'\n","scheduler = 'stepLR'\n","step_size = 30\n","EPOCHS = 100\n","weight_decay = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679696676017,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"-FLdigvugg0_"},"outputs":[],"source":["class multiClassHingeLoss(nn.Module):\n","    def __init__(self, p=1, margin=1, device='cpu', size_average=True):\n","        super(multiClassHingeLoss, self).__init__()\n","        self.margin=margin\n","        self.size_average=size_average\n","        self.device = device\n","    def forward(self, output, y):\n","        output_y=output[torch.arange(0,y.size()[0]).long().to(self.device),y.data.to(self.device)].view(-1,1) #it is a (Batch Size x 1) tensor, having entries that are x[y]\n","        loss=output-output_y+self.margin #this has self.margin in position y and the difference between the entry of x and x[y] in the other positions\n","        #remove i=y items\n","        loss[torch.arange(0,y.size()[0]).long().to(self.device),y.data.to(self.device)]=0 #sets to 0 the entry in position y, instead of having self.margin\n","        #max(0,_)\n","        loss[loss<0]=0 #sets to 0 the entries of loss where we have negative numbers, i.e. those meeting the margin (there is a higher difference than the margin between x[y] and x[i])\n","        #sum up\n","        loss=torch.sum(loss)\n","        if(self.size_average):\n","            loss/=output.size()[0]\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679696676018,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"Qw7n345izKsW"},"outputs":[],"source":["class Normalisation(torch.nn.Module):\n","    def __init__(self, means=(0.485, 0.456, 0.406), stds=(0.229, 0.224, 0.225)): #cifar100 \n","        super().__init__()\n","        assert len(means) == len(stds)\n","        self.means = means\n","        self.stds = stds\n","    \n","    def forward(self, x):\n","        return (x - torch.tensor(self.means, device=x.device).view(1, len(self.means), 1, 1)) / torch.tensor(self.stds, device=x.device).view(1, len(self.means), 1, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1679696676529,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"dBXXqqqSiiuN"},"outputs":[],"source":["import torch.optim as optim\n","\n","marginList = [0.07,0.15,0.3]\n","epsilons = [0.0, 8/255, 16/255, 36/255, 0.3, 0.5, 0.6, 0.8, 1.0]\n","\n","robust_accuracy = np.zeros((len(marginList),len(epsilons)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2835435,"status":"error","timestamp":1679699512776,"user":{"displayName":"Davide Murari","userId":"06157762911889113152"},"user_tz":0},"id":"ZDmVEJTlglQR","outputId":"efde55f5-1eee-41de-9b5e-9f40ec21bf6d"},"outputs":[],"source":["for iterate,margin in enumerate(marginList):\n","\n","  ResNet = Network2(3,32,64,128,4,4,4)\n","  ResNet.to(device);\n","\n","  pretrained_dict = torch.load(f\"cif10_trained_model_margin_{margin}.pt\",map_location=device)\n","  ResNet.load_state_dict(pretrained_dict, strict=False)\n","\n","  criterion = multiClassHingeLoss(margin = margin)\n","  optimizer = optim.SGD(ResNet.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n","\n","  EPOCHS = 100\n","  for epoch in range(EPOCHS):\n","      losses = []\n","      running_loss = 0\n","      correct = 0\n","      count = 0\n","      for i, inp in enumerate(trainloader):\n","          inputs, labels = inp\n","          inputs, labels = inputs.to(device), labels.to(device)\n","          optimizer.zero_grad()\n","      \n","          outputs = ResNet(inputs)\n","          loss = criterion(outputs, labels)\n","          losses.append(loss.item())\n","          loss.backward()\n","\n","          optimizer.step()\n","          running_loss += loss.item()\n","\n","          with torch.no_grad():\n","            _, predicted = torch.max(outputs.data, 1)\n","            count += 1\n","            correct += (predicted == labels.to(device)).sum().item() / len(inputs) #percentage of correct ones\n","          \n","          if i%100 == 0 and i > 0:\n","              print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n","              running_loss = 0.0\n","      \n","      #Check current accuracy\n","      correct = 0\n","      total = 0\n","      \n","      ResNet.eval()\n","      with torch.no_grad():\n","          for data in testloader:\n","              images, labels = data\n","              images.shape\n","              # calculate outputs by running images through the network\n","              outputs = ResNet(images.to(device))\n","              # the class with the highest energy is what we choose as prediction\n","              _, predicted = torch.max(outputs.data, 1)\n","              total += labels.size(0)\n","              correct += (predicted == labels.to(device)).sum().item()\n","          print('Current accuracy on 10000 test images: %d %%' % (\n","              100 * correct / total))\n","\n","      ResNet.train()\n","      scheduler.step()\n","      if epoch%10 == 0 and epoch>0:\n","          lr=optimizer.param_groups[0][\"lr\"]\n","  print('Training Done')\n","\n","  transform_test_rob = transforms.Compose([\n","    transforms.ToTensor()\n","  ])\n","  batch_size = 1024\n","  testset_rob = torchvision.datasets.CIFAR100(root='./data', train=False,\n","                                        download=True, transform=transform_test_rob)\n","  testloader_rob = torch.utils.data.DataLoader(testset_rob, batch_size=batch_size,\n","                                          shuffle=False, num_workers=2)\n","  images, labels = next(iter(testloader_rob))\n","  images, labels = images.to(device), labels.to(device)\n","  model = nn.Sequential(Normalisation(),ResNet).eval()\n","  fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n","  \n","  acc = fb.utils.accuracy(fmodel, images, labels)\n","  attack = fb.attacks.L2PGD(steps=10)\n","  \n","  _, advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n","  robust_accuracy[iterate] = torch.mean((1-1.*success),axis=1).detach().cpu().numpy()\n","\n","  fig = plt.figure(figsize=(20,10))\n","  plt.plot(epsilons,robust_accuracy[iterate],'r-*',label=\"Experimental\")\n","  plt.xlabel(r\"$\\varepsilon$\",fontsize=20)\n","  plt.ylabel(\"Robust accuracy\",fontsize=20)\n","  plt.xticks(fontsize=20)\n","  plt.yticks(fontsize=20)\n","  plt.legend(fontsize=20,loc=1)\n","  plt.title(f\"L2 robustness. Trained with margin = {margin}. Test accuracy = {round(acc * 100,2)}%\",fontsize=20);\n","\n","  plt.savefig(f'Cifar100_L2margin_{margin}.png')\n","\n","  dataForTxt = robust_accuracy[iterate]\n","  destination = f\"Cifar100_updateMargin_{margin}.txt\"\n","  np.savetxt(destination, dataForTxt.reshape(-1,1))\n","\n","  torch.save(ResNet.state_dict(), f\"cif100_trained_model_margin_{margin}.pt\")"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1G-5dns_nvCWy-Fi0zFLIA7rHzBCZcAlM","timestamp":1658235119181},{"file_id":"https://github.com/dadeslam/dynamicalSystemsUnderstandingRESNETS/blob/main/Benchmark_Resnet.ipynb","timestamp":1638861908629}]},"kernelspec":{"display_name":"Python 3.11.3 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
